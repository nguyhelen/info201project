---
title: "Final Report"
author: "Helen Nguyen"
date: "2025-03-04"
output: html_document
---

```{r}
library(tidyverse)
library(readxl)

## Loading data
MHI <- read_delim("MedianHouseholdIncome2015.csv", show_col_types = FALSE) # Median Household Income
PK <- read_delim("PoliceKillingsUS.csv", show_col_types = FALSE) # Police Killings
Pop <- read_excel("nst-est2019-01.xlsx") # Population by state
PR <- read_delim("PercentagePeopleBelowPovertyLevel.csv", show_col_types = FALSE) #Poverty rate
```
```{r}
## PR cleaning & reshaping
colnames(PR)

names(PR)[names(PR) == "Geographic Area"] <- "state"

PR_clean <- PR %>%
  select(state, poverty_rate) %>%
  filter(!is.na(state) & !is.na(poverty_rate)) %>%
  group_by(state) %>%
  mutate(poverty_rate = as.numeric(poverty_rate)) %>%
  summarize(avg_poverty_rate = mean(poverty_rate, na.rm = TRUE))
head(PR_clean)

min(PR_clean$avg_poverty_rate)
max(PR_clean$avg_poverty_rate)
mean(PR_clean$avg_poverty_rate)

```


```{r}
## renaming the two columns for Pop data set
names(Pop)[names(Pop) == "table with row headers in column A and column headers in rows 3 through 4. (leading dots indicate sub-parts)"] <- "state"
names(Pop)[names(Pop) == "...9"] <- "popEst2015"
Pop$state <- str_remove(Pop$state, "^\\.") # Gets rid of the "." in the data for States


# Gets rid of the first few rows & only shows states abbreviations and population during 2015
Pop <- Pop %>%
  select(state, popEst2015) %>%
  slice(-(1:8)) %>%
  mutate(state = state.abb[match(state, state.name)], 
                            state = replace(state, 9, "DC"))

## Pop has missing values and have been cleaned
Pop_clean <- Pop %>%
    filter(!is.na(state) & !is.na(popEst2015))
nrow(Pop_clean)
head(Pop_clean)
```

```{r}
## MHI has missing income values which have been cleaned.
MHI_clean <- MHI %>%
  filter(!is.na(`Median Income`) & `Median Income` != "(X)" & `Median Income` != "-")

## changing column name for MHI
names(MHI_clean)[names(MHI_clean) == "Geographic Area"] <- "state"
names(MHI_clean)[names(MHI_clean) == "Median Income"] <- "median_income"

MHI_clean <- MHI_clean %>%
  select(state, median_income) %>%
  group_by(state) %>%
  mutate(median_income = as.numeric(median_income)) %>%
  summarize(median_income = mean(median_income, na.rm = TRUE))

head(MHI_clean)
```

```{r}
## PK has been cleaned from missing values and has the sum of killings per state
PK_clean <- PK %>%
  select(state) %>%
  filter(!is.na(state)) %>%
  group_by(state) %>%
  summarize(PoliceKillings = n())

head(PK_clean)
```

```{r}
## Merging
groupDataSet <- PK_clean %>%
  full_join(MHI_clean, by = "state") %>%
  full_join(Pop_clean, by = "state") %>%
  full_join(PR_clean, by = "state")

head(groupDataSet)
```
```{r}
## RQ01
groupDataSetRQ1 <- groupDataSet %>%
  mutate(popEst2015 = as.numeric(popEst2015),
         killings_per_100k = (PoliceKillings / popEst2015) * 100000)%>%
  mutate(log_killings_per_100k = log(killings_per_100k + 1))

# Plotting the merged data sets to answer RQ01
ggplot(groupDataSetRQ1, aes(x = median_income, y = log_killings_per_100k)) +
  geom_point(alpha = 0.6, color = "red") +
  geom_smooth(method = "lm", se = TRUE, color = "blue") + 
  labs(
    title = "Log(Violence per 100k Residents) vs. Median Income on State Level (2015)",
    x = "Average Median Household Income (USD)",
    y = "Log(Violence per 100k Residents)"
  ) +
  theme_minimal()
```
```{r}
#testing co-relation
cor.test(groupDataSetRQ1$median_income, groupDataSetRQ1$log_killings_per_100k, method = "pearson")
```

### RQ 01: What is the relationship between median household income and police killings across the States in US?

From our data visualization, a negative co-relation was found. From the Pearson's co-relation, p = 0.007 which indicates significant statistic relevance. And the moderate negative co-relation can be interpreted as - "As median household income increases, police killings per 100K residents tend to decrease."

Our scatter plot shows a downward trend reinforcing the negative co-relation. The blue trend line has a negative slope, meaning high-income states generally experience fewer violent police incidents per capita.This suggests that socioeconomic factors may influence the rate of police brutality.

Note: A log transformation was applied to handle skewness in the data. The log reduced the influence of extreme values and made the relationship more interpret able.

```{r}
## RQ2

```
### RQ 02: Do states with higher poverty rates experience higher rates of police killings?

```{r}
## RQ3
groupDataSetRQ3 <- groupDataSet %>%
  select(state, popEst2015, avg_poverty_rate) %>%
  mutate(
    region = case_when(
      state %in% c("ME", "NH", "VT", "MA", "RI", "CT", "NY", "NJ", "PA") ~ "NE",  # Northeast
      state %in% c("OH", "IN", "IL", "MI", "WI", "MO", "IA", "MN", "ND", "SD", "NE", "KS") ~ "MW",  # Midwest
      state %in% c("DE", "MD", "DC", "VA", "NC", "SC", "GA", "FL", "KY", "TN", "AL", "MS", "AR", "LA", "OK", "TX", "WV") ~ "S",  # South
      state %in% c("MT", "WY", "CO", "ID", "UT", "NV", "AZ", "NM", "AK", "WA", "OR", "CA", "HI") ~ "W"  # West
    )
  ) %>%
  group_by(region) %>%
  summarise(
    avg_poverty_rate_region = mean(avg_poverty_rate, na.rm = TRUE),  # Average poverty rate per region
    avg_population_region = mean(popEst2015, na.rm = TRUE)  # Average population per region
  ) %>%
  mutate(avg_population_region = as.numeric(avg_population_region),
         avg_poverty_rate_region = as.numeric(avg_poverty_rate_region))
head(groupDataSetRQ3)

ggplot(groupDataSetRQ3) +
  geom_col(aes(x = region, y = avg_poverty_rate_region, fill = region), position = "dodge") +
  geom_col(aes(x = region, y = avg_population_region, fill = region), alpha = 0.5, position = "dodge") +
  labs(
    title = "Average Poverty Rate and Population Size per Region",
    x = "Region",
    y = "Value"
  ) +
  theme_minimal()

```

### RQ 03: How is the poverty rate related to state population size? Do larger states tend to have higher or lower poverty rates?

```{r}
## RQ4
library(usmap)
library(viridis)
groupDataSetRQ4 <- groupDataSet %>%
  mutate(popEst2015 = as.numeric(popEst2015),
         killings_per_100k = (PoliceKillings / popEst2015) * 100000)

plot_usmap(data = groupDataSetRQ4, values = "killings_per_100k", regions = "states") +
  scale_fill_gradientn(colors = c("#F9FBF2", "#FFEDE1", "#D7F9FF", "#AFCBFF", "#0E1C36"), name = "Police Killings") +
  theme_minimal() +
  labs(title = "Police Killings per 100k Residents by State in the U.S.",
       subtitle = "Darker states indicate higher police killings")
```
### RQ 04: Is there a specific area that has significantly high police brutality in the US?

New Mexico has a significantly high police brutality rate in the U.S.

